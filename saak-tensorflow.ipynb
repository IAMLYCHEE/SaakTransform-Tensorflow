{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#input: a list of images\n",
    "def plotFigures(images):\n",
    "    imageAmount = len(images)\n",
    "    plt.figure(1)\n",
    "    n_columns = 6\n",
    "    n_rows = np.ceil(imageAmount/n_columns)+1\n",
    "    sideLength = np.sqrt(len(images[0]))\n",
    "    \n",
    "    for i in range(imageAmount):\n",
    "        plt.subplot(n_rows,n_columns,i+1)\n",
    "        plt.imshow(np.reshape(images[i],[sideLength.astype(int),sideLength.astype(int)]),cmap=\"gray\")\n",
    "#end\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets('./data')\n",
    "trainDatas = mnist.train.next_batch(1000)\n",
    "imageDatas = trainDatas[0]\n",
    "labelDatas = trainDatas[1]\n",
    "# print(imageDatas[0].shape)\n",
    "# images = []\n",
    "# for i in range(10):\n",
    "#     images.append(imageDatas[i])\n",
    "# plotFigures(images)\n",
    "# plt.show()\n",
    "\n",
    "#define a function to transform image dataset to batch set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_pca_shape(datasets,depth):\n",
    "    factor=np.power(2,depth)\n",
    "    length=32/factor\n",
    "    print ('fit_pca_shape: length: {}'.format(length))\n",
    "    idx1=range(0,int(length),2)\n",
    "    idx2=[i+2 for i in idx1]\n",
    "    print ('fit_pca_shape: idx1: {}'.format(idx1))\n",
    "    data_lattice=[datasets[:,:,i:j,k:l] for ((i,j),(k,l)) in product(zip(idx1,idx2),zip(idx1,idx2))]\n",
    "    data_lattice=np.array(data_lattice)\n",
    "    print ('fit_pca_shape: data_lattice.shape: {}'.format(data_lattice.shape))\n",
    "\n",
    "    #shape reshape\n",
    "    data=np.reshape(data_lattice,(data_lattice.shape[0]*data_lattice.shape[1],data_lattice.shape[2],2,2))\n",
    "    print ('fit_pca_shape: reshape: {}'.format(data.shape))\n",
    "    return data\n",
    "\n",
    "\n",
    "def PCA_and_augment(data_in,number_important):\n",
    "    # data reshape\n",
    "    data=np.reshape(data_in,(data_in.shape[0],-1))\n",
    "    print( 'PCA_and_augment: {}'.format(data.shape))\n",
    "    # mean removal\n",
    "    mean = np.mean(data, axis=0)\n",
    "    datas_mean_remov = data - mean\n",
    "    print( 'PCA_and_augment meanremove shape: {}'.format(datas_mean_remov.shape))\n",
    "\n",
    "    # PCA, retain all components\n",
    "    pca=PCA(n_components = number_important)\n",
    "    pca.fit(datas_mean_remov)\n",
    "    comps=pca.components_\n",
    "\n",
    "    # augment, DC component doesn't\n",
    "    comps_aug=[vec*(-1) for vec in comps]\n",
    "    comps_complete=np.vstack((comps,comps_aug))\n",
    "    shapeComps = comps.shape\n",
    "    mean_kernel = np.ones(shapeComps[1])\n",
    "    mean_kernel = mean_kernel / np.sqrt(shapeComps[1])\n",
    "    comps_complete = np.vstack((comps_complete,mean_kernel))\n",
    "    print( 'PCA_and_augment comps_complete shape: {}'.format(comps_complete.shape))\n",
    "    return comps,comps_complete\n",
    "\n",
    "# def one_stage_saak_trans(datasets=None,depth=0,number_important=3):\n",
    "\n",
    "#     print ('one_stage_saak_trans: datasets.shape {}'.format(datasets.shape))\n",
    "#     input_channels=datasets.shape[1]\n",
    "\n",
    "#     # change data shape, (14*60000,4)\n",
    "#     data_flatten=fit_pca_shape(datasets,depth)\n",
    "\n",
    "#     # augmented components\n",
    "#     comps,comps_complete=PCA_and_augment(data_flatten,number_important)\n",
    "#     print ('one_stage_saak_trans: comps_complete: {}'.format(comps_complete.shape))\n",
    "#     # print('one_saak_trans, non-aug kernel size:{}'.format(comps.shape))\n",
    "\n",
    "#     # get filter and datas, (7,1,2,2) (60000,1,32,32)\n",
    "#     filters=ret_filt_patches(comps_complete,input_channels)\n",
    "#     print ('one_stage_saak_trans: filters: {}'.format(filters.shape))\n",
    "\n",
    "#     # output (60000,7,14,14)\n",
    "#     relu_output,filt=conv_and_relu(filters,datasets,stride=2)\n",
    "\n",
    "#     data=relu_output.data.numpy()\n",
    "#     print ('one_stage_saak_trans: output: {}'.format(data.shape))\n",
    "#     return data,filt,relu_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this block is to test the tf.nn.conv2d\n",
    "print(imageDatas.shape)\n",
    "imageData = imageDatas[8]\n",
    "sideLength = np.sqrt(len(imageData))\n",
    "plt.imshow(np.reshape(imageData,[sideLength.astype(int),sideLength.astype(int)]),cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "# get the components\n",
    "pcaDataSet = fit_pca_shape(imageDatas,0)\n",
    "w,w_aug = PCA_and_anugment(pcaDataSet,0)\n",
    "\n",
    "# tf.nn.conv2d(imageData,W, strides = [1,2,2,1],padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from data.datasets import MNIST\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from itertools import product\n",
    "from sklearn import svm\n",
    "\n",
    "# argument parsing\n",
    "print(torch.__version__)\n",
    "batch_size = 1\n",
    "test_batch_size = 1\n",
    "kwargs = {}\n",
    "train_loader = data_utils.DataLoader(MNIST(root='./data', train=True, process=False, transform=transforms.Compose([\n",
    "    transforms.Scale((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])), batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "test_loader = data_utils.DataLoader(MNIST(root='./data', train=False, process=False, transform=transforms.Compose([\n",
    "    transforms.Scale((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])), batch_size=test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "# @ For demo use, only extracts the first 1000 samples\n",
    "# '''\n",
    "def create_numpy_dataset():\n",
    "    datasets = []\n",
    "    datalabel = []\n",
    "    for data in train_loader:\n",
    "        data_numpy = data[0].numpy()\n",
    "        data_numpy = np.squeeze(data_numpy)\n",
    "        datasets.append(data_numpy)\n",
    "        datalabel.append(data[1].numpy())\n",
    "\n",
    "    datasets = np.array(datasets)\n",
    "    datasets=np.expand_dims(datasets,axis=1)\n",
    "    print( 'Numpy dataset shape is {}'.format(datasets.shape))\n",
    "    return datasets[:60000],datalabel[:60000]\n",
    "\n",
    "def create_numpy_testdataset():\n",
    "    datasets = []\n",
    "    datalabel = []\n",
    "    for data in test_loader:\n",
    "        data_numpy = data[0].numpy()\n",
    "        data_numpy = np.squeeze(data_numpy)\n",
    "        datasets.append(data_numpy)\n",
    "        datalabel.append(data[1].numpy())\n",
    "\n",
    "    datasets = np.array(datasets)\n",
    "    datasets=np.expand_dims(datasets,axis=1)\n",
    "    print( 'Numpy dataset shape is {}'.format(datasets.shape))\n",
    "    return datasets[:10000],datalabel[:10000]\n",
    "\n",
    "\n",
    "# @ data: flatten patch data: (14*14*60000,1,2,2)\n",
    "# @ return: augmented anchors\n",
    "# '''\n",
    "def PCA_and_augment(data_in,number_important):\n",
    "    # data reshape\n",
    "    data=np.reshape(data_in,(data_in.shape[0],-1))\n",
    "    print( 'PCA_and_augment: {}'.format(data.shape))\n",
    "    # mean removal\n",
    "    mean = np.mean(data, axis=0)\n",
    "    datas_mean_remov = data - mean\n",
    "    print( 'PCA_and_augment meanremove shape: {}'.format(datas_mean_remov.shape))\n",
    "\n",
    "    # PCA, retain all components\n",
    "    pca=PCA(n_components = number_important)\n",
    "    pca.fit(datas_mean_remov)\n",
    "    comps=pca.components_\n",
    "\n",
    "    # augment, DC component doesn't\n",
    "    comps_aug=[vec*(-1) for vec in comps]\n",
    "    comps_complete=np.vstack((comps,comps_aug))\n",
    "    shapeComps = comps.shape\n",
    "    mean_kernel = np.ones(shapeComps[1])\n",
    "    mean_kernel = mean_kernel / np.sqrt(shapeComps[1])\n",
    "    comps_complete = np.vstack((comps_complete,mean_kernel))\n",
    "    print( 'PCA_and_augment comps_complete shape: {}'.format(comps_complete.shape))\n",
    "    return comps,comps_complete\n",
    "\n",
    "\n",
    "\n",
    "# '''\n",
    "# @ datasets: numpy data as input\n",
    "# @ depth: determine shape, initial: 0\n",
    "# '''\n",
    "\n",
    "def fit_pca_shape(datasets,depth):\n",
    "    factor=np.power(2,depth)\n",
    "    length=32/factor\n",
    "    print ('fit_pca_shape: length: {}'.format(length))\n",
    "    idx1=range(0,int(length),2)\n",
    "    idx2=[i+2 for i in idx1]\n",
    "    print ('fit_pca_shape: idx1: {}'.format(idx1))\n",
    "    data_lattice=[datasets[:,:,i:j,k:l] for ((i,j),(k,l)) in product(zip(idx1,idx2),zip(idx1,idx2))]\n",
    "    data_lattice=np.array(data_lattice)\n",
    "    print ('fit_pca_shape: data_lattice.shape: {}'.format(data_lattice.shape))\n",
    "\n",
    "    #shape reshape\n",
    "    data=np.reshape(data_lattice,(data_lattice.shape[0]*data_lattice.shape[1],data_lattice.shape[2],2,2))\n",
    "    print ('fit_pca_shape: reshape: {}'.format(data.shape))\n",
    "    return data\n",
    "\n",
    "\n",
    "# '''\n",
    "# @ Prepare shape changes.\n",
    "# @ return filters and datasets for convolution\n",
    "# @ aug_anchors: [7,4] -> [7,input_shape,2,2]\n",
    "# @ output_datas: [60000*num_patch*num_patch,channel,2,2]\n",
    "\n",
    "# '''\n",
    "def ret_filt_patches(aug_anchors,input_channels):\n",
    "    shape=int(aug_anchors.shape[1]/4)\n",
    "    num=aug_anchors.shape[0]\n",
    "    filt=np.reshape(aug_anchors,(num,shape,4))\n",
    "\n",
    "    # reshape to kernels, (7,shape,2,2)\n",
    "    filters=np.reshape(filt,(num,shape,2,2))\n",
    "\n",
    "    # reshape datasets, (60000*shape*shape,shape,28,28)\n",
    "    # datasets=np.expand_dims(dataset,axis=1)\n",
    "\n",
    "    return filters\n",
    "\n",
    "\n",
    "\n",
    "# '''\n",
    "# @ input: numpy kernel and data\n",
    "# @ output: conv+relu result\n",
    "# '''\n",
    "def conv_and_relu(filters,datasets,stride=2):\n",
    "    # torch data change\n",
    "    filters_t=torch.from_numpy(filters)\n",
    "    datasets_t=torch.from_numpy(datasets)\n",
    "\n",
    "    # Variables\n",
    "    filt=Variable(filters_t).type(torch.FloatTensor)\n",
    "    data=Variable(datasets_t).type(torch.FloatTensor)\n",
    "\n",
    "    # Convolution\n",
    "    output=F.conv2d(data,filt,stride=stride)\n",
    "\n",
    "    # Relu\n",
    "    relu_output=F.relu(output)\n",
    "\n",
    "    return relu_output,filt\n",
    "\n",
    "\n",
    "\n",
    "# @ One-stage Saak transform\n",
    "# @ input: datasets [60000,channel, size,size]\n",
    "# '''\n",
    "def one_stage_saak_trans(datasets=None,depth=0,number_important=3):\n",
    "\n",
    "\n",
    "    # load dataset, (60000,1,32,32)\n",
    "    # input_channel: 1->7\n",
    "    print ('one_stage_saak_trans: datasets.shape {}'.format(datasets.shape))\n",
    "    input_channels=datasets.shape[1]\n",
    "\n",
    "    # change data shape, (14*60000,4)\n",
    "    data_flatten=fit_pca_shape(datasets,depth)\n",
    "\n",
    "    # augmented components\n",
    "    comps,comps_complete=PCA_and_augment(data_flatten,number_important)\n",
    "    print ('one_stage_saak_trans: comps_complete: {}'.format(comps_complete.shape))\n",
    "    # print('one_saak_trans, non-aug kernel size:{}'.format(comps.shape))\n",
    "\n",
    "    # get filter and datas, (7,1,2,2) (60000,1,32,32)\n",
    "    filters=ret_filt_patches(comps_complete,input_channels)\n",
    "    print ('one_stage_saak_trans: filters: {}'.format(filters.shape))\n",
    "\n",
    "    # output (60000,7,14,14)\n",
    "    relu_output,filt=conv_and_relu(filters,datasets,stride=2)\n",
    "\n",
    "    data=relu_output.data.numpy()\n",
    "    print ('one_stage_saak_trans: output: {}'.format(data.shape))\n",
    "    return data,filt,relu_output\n",
    "\n",
    "\n",
    "\n",
    "# '''\n",
    "# @ Multi-stage Saak transform\n",
    "# '''\n",
    "def multi_stage_saak_trans():\n",
    "    filters = []\n",
    "    outputs = []\n",
    "    data,datalabel=create_numpy_dataset()\n",
    "    dataset=data\n",
    "    num=0\n",
    "    img_len=data.shape[-1]\n",
    "    while(img_len>=2):\n",
    "        num+=1\n",
    "        img_len/=2\n",
    "\n",
    "    stage_number = {0:3,1:4,2:7,3:6,4:8}\n",
    "    for i in range(num):\n",
    "        print ('{} stage of saak transform: '.format(i))\n",
    "        data,filt,output=one_stage_saak_trans(data,depth=i,number_important=stage_number[i])\n",
    "        filters.append(filt)\n",
    "        outputs.append(output)\n",
    "        print ('')\n",
    "\n",
    "\n",
    "    return dataset,filters,outputs,datalabel\n",
    "\n",
    "\n",
    "def multi_stage_saak_trans_test():\n",
    "    filters = []\n",
    "    outputs = []\n",
    "\n",
    "    data,datalabel=create_numpy_testdataset()\n",
    "    dataset=data\n",
    "    num=0\n",
    "    img_len=data.shape[-1]\n",
    "    while(img_len>=2):\n",
    "        num+=1\n",
    "        img_len/=2\n",
    "\n",
    "    stage_number = {0:3,1:4,2:7,3:6,4:8}\n",
    "    for i in range(num):\n",
    "        print ('{} stage of saak transform: '.format(i))\n",
    "        data,filt,output=one_stage_saak_trans(data,depth=i,number_important=stage_number[i])\n",
    "        filters.append(filt)\n",
    "        outputs.append(output)\n",
    "\n",
    "\n",
    "    return dataset,filters,outputs,datalabel\n",
    "\n",
    "\n",
    "from sklearn import feature_selection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_selection_pca(k_best_fscore, n_comps, image_amount, outputs, datalabel):\n",
    "    features = np.zeros((image_amount, 2677))\n",
    "    for i in range(image_amount):\n",
    "        feature = []\n",
    "        for j in range(len(outputs)):\n",
    "            stagej = outputs[j].data.numpy()\n",
    "            feature = np.concatenate([feature, stagej[i, :].flatten()])\n",
    "        features[i, :] = feature\n",
    "\n",
    "    model = feature_selection.SelectKBest(score_func=feature_selection.f_classif, k=k_best_fscore)\n",
    "    datalabel = np.asarray(datalabel)\n",
    "    datalabel = np.squeeze(datalabel)\n",
    "    print(datalabel.shape)\n",
    "\n",
    "    print(features.shape)\n",
    "    topFeatures = model.fit_transform(features, datalabel)\n",
    "    indexs = model.get_support()\n",
    "    print(indexs.shape)\n",
    "    print(\"best f-score features size:{}\".format(topFeatures.shape))\n",
    "    pcaComNumber = n_comps\n",
    "    pca = PCA(n_components=pcaComNumber)\n",
    "    pcaTopFeatures = pca.fit_transform(topFeatures)\n",
    "    print(\"after another round pca , feature size:{}\".format(pcaTopFeatures.shape))\n",
    "    return pcaTopFeatures, indexs, pca\n",
    "\n",
    "\n",
    "def feature_selection_pca_for_test( image_amount, outputs, learnedIndex, pca):\n",
    "    features = np.zeros((image_amount, 2677))\n",
    "    for i in range(image_amount):\n",
    "        feature = []\n",
    "        for j in range(len(outputs)):\n",
    "            stagej = outputs[j].data.numpy()\n",
    "            feature = np.concatenate([feature, stagej[i, :].flatten()])\n",
    "        features[i, :] = feature\n",
    "\n",
    "    topFeatures = features[:, learnedIndex]\n",
    "    print(\"best f-score features size:{}\".format(topFeatures.shape))\n",
    "    pcaTopFeatures = pca.transform(topFeatures)\n",
    "    print(\"after another round pca , feature size:{}\".format(pcaTopFeatures.shape))\n",
    "    return pcaTopFeatures\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     dataset, filters, outputs, datalabel = multi_stage_saak_trans()\n",
    "#     datalabel = np.asarray(datalabel)\n",
    "#     datalabel = np.squeeze(datalabel)\n",
    "\n",
    "#     pcaTopFeatures, indexs, pca = feature_selection_pca(1000, 128, 60000, outputs, datalabel)\n",
    "\n",
    "#     print(\"svm training start\")\n",
    "#     clf = svm.SVC()\n",
    "#     clf.fit(pcaTopFeatures,datalabel)\n",
    "#     print(\"svm training finished\")\n",
    "\n",
    "#     datatestSet, filters, outputsTest, datalabeltest = multi_stage_saak_trans_test()\n",
    "#     pcaTopFeaturesTest = feature_selection_pca_for_test(10000,outputsTest,indexs,pca)\n",
    "#     error = 0\n",
    "#     error_index = []\n",
    "#     for i in range(10000):\n",
    "#         if(clf.predict([pcaTopFeaturesTest[i]]) != datalabeltest[i]):\n",
    "#             error = error +1\n",
    "#             error_index.append(i)\n",
    "#     print(error/10000)\n",
    "#     print(error_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy dataset shape is (60000, 1, 32, 32)\n",
      "0 stage of saak transform: \n",
      "one_stage_saak_trans: datasets.shape (60000, 1, 32, 32)\n",
      "fit_pca_shape: length: 32.0\n",
      "fit_pca_shape: idx1: range(0, 32, 2)\n",
      "fit_pca_shape: data_lattice.shape: (256, 60000, 1, 2, 2)\n",
      "fit_pca_shape: reshape: (15360000, 1, 2, 2)\n",
      "PCA_and_augment: (15360000, 4)\n",
      "PCA_and_augment meanremove shape: (15360000, 4)\n",
      "PCA_and_augment comps_complete shape: (7, 4)\n",
      "one_stage_saak_trans: comps_complete: (7, 4)\n",
      "one_stage_saak_trans: filters: (7, 1, 2, 2)\n",
      "one_stage_saak_trans: output: (60000, 7, 16, 16)\n",
      "\n",
      "1 stage of saak transform: \n",
      "one_stage_saak_trans: datasets.shape (60000, 7, 16, 16)\n",
      "fit_pca_shape: length: 16.0\n",
      "fit_pca_shape: idx1: range(0, 16, 2)\n",
      "fit_pca_shape: data_lattice.shape: (64, 60000, 7, 2, 2)\n",
      "fit_pca_shape: reshape: (3840000, 7, 2, 2)\n",
      "PCA_and_augment: (3840000, 28)\n",
      "PCA_and_augment meanremove shape: (3840000, 28)\n",
      "PCA_and_augment comps_complete shape: (9, 28)\n",
      "one_stage_saak_trans: comps_complete: (9, 28)\n",
      "one_stage_saak_trans: filters: (9, 7, 2, 2)\n",
      "one_stage_saak_trans: output: (60000, 9, 8, 8)\n",
      "\n",
      "2 stage of saak transform: \n",
      "one_stage_saak_trans: datasets.shape (60000, 9, 8, 8)\n",
      "fit_pca_shape: length: 8.0\n",
      "fit_pca_shape: idx1: range(0, 8, 2)\n",
      "fit_pca_shape: data_lattice.shape: (16, 60000, 9, 2, 2)\n",
      "fit_pca_shape: reshape: (960000, 9, 2, 2)\n",
      "PCA_and_augment: (960000, 36)\n",
      "PCA_and_augment meanremove shape: (960000, 36)\n",
      "PCA_and_augment comps_complete shape: (15, 36)\n",
      "one_stage_saak_trans: comps_complete: (15, 36)\n",
      "one_stage_saak_trans: filters: (15, 9, 2, 2)\n",
      "one_stage_saak_trans: output: (60000, 15, 4, 4)\n",
      "\n",
      "3 stage of saak transform: \n",
      "one_stage_saak_trans: datasets.shape (60000, 15, 4, 4)\n",
      "fit_pca_shape: length: 4.0\n",
      "fit_pca_shape: idx1: range(0, 4, 2)\n",
      "fit_pca_shape: data_lattice.shape: (4, 60000, 15, 2, 2)\n",
      "fit_pca_shape: reshape: (240000, 15, 2, 2)\n",
      "PCA_and_augment: (240000, 60)\n",
      "PCA_and_augment meanremove shape: (240000, 60)\n",
      "PCA_and_augment comps_complete shape: (13, 60)\n",
      "one_stage_saak_trans: comps_complete: (13, 60)\n",
      "one_stage_saak_trans: filters: (13, 15, 2, 2)\n",
      "one_stage_saak_trans: output: (60000, 13, 2, 2)\n",
      "\n",
      "4 stage of saak transform: \n",
      "one_stage_saak_trans: datasets.shape (60000, 13, 2, 2)\n",
      "fit_pca_shape: length: 2.0\n",
      "fit_pca_shape: idx1: range(0, 2, 2)\n",
      "fit_pca_shape: data_lattice.shape: (1, 60000, 13, 2, 2)\n",
      "fit_pca_shape: reshape: (60000, 13, 2, 2)\n",
      "PCA_and_augment: (60000, 52)\n",
      "PCA_and_augment meanremove shape: (60000, 52)\n",
      "PCA_and_augment comps_complete shape: (17, 52)\n",
      "one_stage_saak_trans: comps_complete: (17, 52)\n",
      "one_stage_saak_trans: filters: (17, 13, 2, 2)\n",
      "one_stage_saak_trans: output: (60000, 17, 1, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def checkOutPutsEachChannel(image,outputs,index):\n",
    "#     output = outputs[index]\n",
    "#     for j in len(outputs):\n",
    "#         stagej = output[j].data.numpy()\n",
    "#         print(stagej)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    dataset, filters, outputs, datalabel = multi_stage_saak_trans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(7, 16, 16)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwlK4RcJ6v8BpN8ybtf7ltMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29408fe2940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABLCAYAAABgOHyfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29408fe2588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    datalabel = np.asarray(datalabel)\n",
    "    datalabel = np.squeeze(datalabel)\n",
    "    \n",
    "    imageData = dataset[19]\n",
    "#     print(imageData.shape)\n",
    "    sideLength = imageData.shape[1]\n",
    "    plt.imshow(np.reshape(imageData,[sideLength,sideLength]),cmap=\"gray\")\n",
    "    plt.figure()\n",
    "#     checkOutPutsEachChannel(imageData,outputs,8)\n",
    "    \n",
    "    print(len(outputs))\n",
    "#     for j in range(5):\n",
    "    stagej = outputs[0].data.numpy()\n",
    "    responsei = stagej[19,:,:,:]\n",
    "    print(responsei.shape)\n",
    "    n_columns = 7;\n",
    "    n_rows = np.floor(responsei.shape[0]/(n_columns+1))+1 \n",
    "    for i in range(responsei.shape[0]):\n",
    "        plt.subplot(n_rows,n_columns,i+1)\n",
    "        plt.imshow(responsei[i,:,:],cmap=\"gray\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
